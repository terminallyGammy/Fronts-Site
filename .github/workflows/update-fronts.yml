name: Update Fronts (SimplyPlural → fronts.json)

on:
  schedule:
    - cron: '*/5 * * * *'
  workflow_dispatch: {}

permissions:
  contents: write

env:
  PAGES_BRANCH: main
  PAGES_DIR: .

jobs:
  update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Pages branch
        uses: actions/checkout@v4
        with:
          ref: ${{ env.PAGES_BRANCH }}
          fetch-depth: 0

      - name: "Debug: show branch & tree"
        shell: bash
        run: |
          echo "On branch: $(git rev-parse --abbrev-ref HEAD)"
          echo "Repo root contents:"; ls -la
          echo "PAGES_DIR contents:"; ls -la "${{ env.PAGES_DIR }}" || true

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Fetch fronters + members + field labels → fronts.json
        shell: bash
        env:
          SP_TOKEN: ${{ secrets.SP_TOKEN }}
          PAGES_DIR: ${{ env.PAGES_DIR }}
        run: |
          set -euo pipefail
          test -n "${SP_TOKEN}" || { echo "ERROR: SP_TOKEN secret is not set"; exit 1; }
          mkdir -p "${PAGES_DIR}"

          # ---------------- 1) systemId ----------------
          echo "→ /v1/me"
          CODE_ME=$(curl -sS -o "${PAGES_DIR}/me.json" -w "%{http_code}" \
            -H "Authorization: ${SP_TOKEN}" -H "Accept: application/json" \
            https://api.apparyllis.com/v1/me || true)
          echo "HTTP ${CODE_ME}"
          [ "${CODE_ME}" = "200" ] || { echo "Cannot fetch /v1/me"; head -c 400 "${PAGES_DIR}/me.json" || true; exit 1; }
          SYSTEM_ID=$(jq -r '.content.systemId // .content.uid // .id' "${PAGES_DIR}/me.json")
          [ -n "${SYSTEM_ID}" ] || { echo "systemId not found"; exit 1; }
          echo "systemId=${SYSTEM_ID}"

          # ---------------- 2) fronters (history) ----------------
          echo "→ /v1/fronters/"
          CODE_F=$(curl -sS -o "${PAGES_DIR}/fh.json" -w "%{http_code}" \
            -H "Authorization: ${SP_TOKEN}" -H "Accept: application/json" \
            https://api.apparyllis.com/v1/fronters/ || true)
          echo "HTTP ${CODE_F}"
          [ "${CODE_F}" = "200" ] || { echo "Cannot get fronters"; head -c 400 "${PAGES_DIR}/fh.json" || true; exit 1; }

          LAST_CHANGE=$(jq -r '[ .[] | .content.lastOperationTime?, .content.startTime? ] | map(select(.!=null)) | max // empty' "${PAGES_DIR}/fh.json")
          : "${LAST_CHANGE:=}"

          # live ids
          LIVE_IDS=$(jq -r '[ .[] | select(.content.live==true) | .content.member ] | unique | .[]?' "${PAGES_DIR}/fh.json" || true)

          # ---------------- 3) members (full list) ----------------
          echo "→ /v1/members/${SYSTEM_ID}"
          CODE_MEM=$(curl -sS -o "${PAGES_DIR}/members.json" -w "%{http_code}" \
            -H "Authorization: ${SP_TOKEN}" -H "Accept: application/json" \
            "https://api.apparyllis.com/v1/members/${SYSTEM_ID}" || true)
          echo "HTTP ${CODE_MEM}"
          [ "${CODE_MEM}" = "200" ] || { echo "Cannot get members"; head -c 400 "${PAGES_DIR}/members.json" || true; exit 1; }

          # ---------------- 4) discover field IDs from CURRENT FRONTERS only ----------------
          echo "Discovering field IDs from current fronters…"
          # Gather content objects for live members
          jq -r --argjson mem "$(cat "${PAGES_DIR}/members.json")" \
               --argjson fh  "$(cat "${PAGES_DIR}/fh.json")" '
            ($fh
              | map(select(.content.live==true))
              | map(.content.member)
              | unique) as $ids
            | [$mem[] | select($ids | index(.id)) | .content] ' > "${PAGES_DIR}/live_members.json"

          # Extract possible field IDs from multiple shapes
          jq -r '
            .[] as $m
            | ( $m.fields        // {} | keys[]? ),
              ( $m.fieldValues   // {} | keys[]? ),
              ( $m.fieldsValue   // {} | keys[]? ),
              ( $m.values        // {} | keys[]? ),
              ( $m.infoFields    // [] | .[]?.id? ),
              ( $m.fields        // [] | .[]?.id? )
          ' "${PAGES_DIR}/live_members.json" \
          | sed '/^$/d' | sort -u > "${PAGES_DIR}/field_ids.txt" || true

          echo "Field IDs found:"
          head -n 30 "${PAGES_DIR}/field_ids.txt" || true

          # ---------------- 5) build fielddefs.json by fetching each definition ----------------
          echo '[]' > "${PAGES_DIR}/fielddefs.json"
          while IFS= read -r FID; do
            [ -n "${FID}" ] || continue
            # try /v1/field/{systemId}/{id} then /v1/field/{id}
            URL1="https://api.apparyllis.com/v1/field/${SYSTEM_ID}/${FID}"
            URL2="https://api.apparyllis.com/v1/field/${FID}"
            CODE=$(curl -sS -o "${PAGES_DIR}/onefield.json" -w "%{http_code}" \
              -H "Authorization: ${SP_TOKEN}" -H "Accept: application/json" "${URL1}" || true)
            if [ "${CODE}" != "200" ]; then
              CODE=$(curl -sS -o "${PAGES_DIR}/onefield.json" -w "%{http_code}" \
                -H "Authorization: ${SP_TOKEN}" -H "Accept: application/json" "${URL2}" || true)
            fi
            if [ "${CODE}" = "200" ]; then
              # normalize into {id,label}
              jq -S --arg id "${FID}" '
                {
                  id: ($id),
                  name: (.name // .label // .title // .id // $id)
                }
              ' "${PAGES_DIR}/onefield.json" > "${PAGES_DIR}/onefield.norm.json"
              jq -S '. + [ input ]' "${PAGES_DIR}/fielddefs.json" "${PAGES_DIR}/onefield.norm.json" > "${PAGES_DIR}/fielddefs.new.json"
              mv "${PAGES_DIR}/fielddefs.new.json" "${PAGES_DIR}/fielddefs.json"
            fi
          done < "${PAGES_DIR}/field_ids.txt"

          # ---------------- 6) Join → fronts.json ----------------
          jq -n \
            --argjson fh  "$(cat "${PAGES_DIR}/fh.json")" \
            --argjson mem "$(cat "${PAGES_DIR}/members.json")" \
            --argjson fdef "$(cat "${PAGES_DIR}/fielddefs.json")" \
            --arg lc "${LAST_CHANGE:-}" '
          # map id -> label
          def to_label_map:
            (reduce .[] as $d ({}; . + { ($d.id // ""): ($d.name // "") }))
            | with_entries(select(.key != "" and .value != ""));

          # get value for a field id from a member content object
          def get_val($m; $id):
            ($m.fieldValues[$id].value // $m.fieldValues[$id]) //
            ($m.fields[$id].value      // $m.fields[$id]) //
            ($m.fieldsValue[$id].value // $m.fieldsValue[$id]) //
            ($m.values[$id].value      // $m.values[$id]) //
            null;

          # object {id->{...}} -> id list
          def obj_ids(o): (o // {}) | keys;

          # normalize sections into pseudo-fields
          def section_fields($m):
            ($m.sections // [])
            | map({ label: (.title // .name // .label // ""), value: (.content // .text // "") })
            | map(select((.label|length)>0 and (.value|length)>0));

          {
            lastChange: (if $lc=="" then null else (try ($lc|tonumber/1000|todate) catch .) end),
            membersFronting: (
              $fh
              | map(select(.content.live==true))
              | map(.content.member)
              | unique
              | map(
                  . as $mid
                  | ( ($mem[] | select(.id==$mid) | .content) // null ) as $m
                  | if $m == null then
                      { id: $mid, displayName: null, pronouns: null, avatar: null, color: null, description: null, fields: [] }
                    else
                      # collect all candidate field ids present on this member
                      ( (obj_ids($m.fields) + obj_ids($m.fieldValues) + obj_ids($m.fieldsValue) + obj_ids($m.values)) | unique ) as $ids
                      | ($fdef | to_label_map) as $labels
                      | (
                          # id-based fields
                          $ids
                          | map({
                              label: ($labels[.] // .),
                              value: (get_val($m; .) // "")
                            })
                          | map(select((.label|length)>0 and (.value|tostring|length)>0))
                        + # section-based fields
                          section_fields($m)
                        )
                        as $all
                      | {
                          id: $mid,
                          displayName: $m.name,
                          pronouns: $m.pronouns,
                          avatar: $m.avatarUrl,
                          color: $m.color,
                          description: ($m.desc // $m.info // null),
                          fields: ($all | unique_by(.label,.value))
                        }
                  end
                )
            )
          }' > "${PAGES_DIR}/fronts.json"

          echo "Wrote $(wc -c < "${PAGES_DIR}/fronts.json") bytes to fronts.json"
          head -c 400 "${PAGES_DIR}/fronts.json" || true; echo

      - name: Validate JSON
        shell: bash
        env:
          PAGES_DIR: ${{ env.PAGES_DIR }}
        run: |
          python - <<'PY'
import json,sys
j=json.load(open('${{ env.PAGES_DIR }}/fronts.json'))
assert 'membersFronting' in j
print('✅ fronts.json is valid; membersFronting:', len(j.get('membersFronting',[])))
PY

      - name: Commit and push if changed
        shell: bash
        env:
          PAGES_BRANCH: ${{ env.PAGES_BRANCH }}
          PAGES_DIR: ${{ env.PAGES_DIR }}
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add "${PAGES_DIR}/fronts.json"
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git commit -m "Update fronts.json [skip ci]"
          git push origin "${PAGES_BRANCH}"
